{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import argv, exit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "class Classificador():\n",
    "\n",
    "    def pre_proc(self, df):\n",
    "\n",
    "        ## Pré processamento do dataset.\n",
    "        # Definindo quais vão ser as categorias enviadas para classificação.\n",
    "        categorias_finais = ['tec', 'esporte', 'ilustrada', 'mercado', 'poder', 'mundo']\n",
    "\n",
    "        categorias_diluidas = list(set(df['category']) - set(categorias_finais))\n",
    "\n",
    "        # Agrupando coluna de tecnologia com ciência.\n",
    "        df[\"category\"]= df[\"category\"].replace(\"ciencia\", \"tec\")\n",
    "\n",
    "        # Criando dataset com categorias finais para teste\n",
    "        docs_classif = df#.copy(deep=True)#.sample(frac=1)\n",
    "        for cat in categorias_diluidas:\n",
    "            docs_classif = docs_classif[docs_classif['category'] != cat]\n",
    "\n",
    "        docs_sem_classif = df#.copy(deep=True)#.sample(frac=1)\n",
    "        for cat in categorias_finais:\n",
    "            docs_sem_classif = docs_sem_classif[docs_sem_classif['category'] != cat]\n",
    "        \n",
    "        return docs_classif, docs_sem_classif\n",
    "    \n",
    "    def dataset_treino(self, docs_classif, docs_sem_classif, modelo):\n",
    "\n",
    "        vetores_treino = list()\n",
    "        classes_treino = list()\n",
    "\n",
    "        vetores_teste = list()\n",
    "        classes_teste = list()\n",
    "\n",
    "        for index, row in docs_classif.iterrows():\n",
    "            try:\n",
    "                vetores_treino.append(modelo['DOC_'+str(index)])\n",
    "                classes_treino.append(row['category'])\n",
    "            except:\n",
    "                print(\"PADRÃO: \", index)\n",
    "\n",
    "        for index, row in docs_sem_classif.iterrows():\n",
    "            try:\n",
    "                vetores_teste.append(modelo['DOC_'+str(index)])\n",
    "                classes_teste.append(row['category'])\n",
    "            except:\n",
    "                print(\"GENÉRICOS: \", index)\n",
    "\n",
    "        docs_classif[\"vetor\"] = vetores_treino\n",
    "        docs_classif[\"classe\"] = classes_treino\n",
    "        docs_sem_classif[\"vetor\"] = vetores_teste\n",
    "\n",
    "    def cross_valid(self, clf, vetores, classes):\n",
    "\n",
    "        scores = cross_val_score(clf, vetores, classes,\\\n",
    "            cv=5, scoring='f1_macro')    \n",
    "        print(\"F1-Measure: \", scores)\n",
    "\n",
    "    def treinar(self, treino, alg):\n",
    "\n",
    "        # Regressão Logistica.\n",
    "        if alg == 1:\n",
    "            clf = LogisticRegression(random_state=0, max_iter=150, solver='sag')#C=0.8)\n",
    "        # Naive Bayes.\n",
    "        elif alg == 2:\n",
    "            clf = GaussianNB()\n",
    "        # Rede Neural.\n",
    "        elif alg == 3:\n",
    "            clf = MLPClassifier(solver='sgd', alpha=1e-5,\\\n",
    "                hidden_layer_sizes=(100, 1), random_state=1, learning_rate= 'adaptive')\n",
    "        else:\n",
    "            clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "            \n",
    "        self.cross_valid(clf, list(treino['vetor']), list(treino['classe']))\n",
    "\n",
    "    def classificar(self, treino, teste, alg):\n",
    "        \n",
    "        # Regressão Logistica.\n",
    "        if alg == 1:\n",
    "            clf = LogisticRegression(random_state=0, max_iter=150, solver='sag')#, C=0.8)\n",
    "        # Naive Bayes.\n",
    "        elif alg == 2:\n",
    "            clf = GaussianNB()\n",
    "        # Rede Neural.\n",
    "        elif alg == 3:\n",
    "            clf = MLPClassifier(solver='sgd', alpha=1e-5,\\\n",
    "                hidden_layer_sizes=(100, 1), random_state=1, learning_rate= 'adaptive', max_iter=300)\n",
    "        else:\n",
    "            clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "        \n",
    "        clf.fit(list(treino['vetor']), list(treino['classe']))\n",
    "\n",
    "        # Classificando as novas amostras.\n",
    "        classificados = clf.predict(list(teste['vetor']))\n",
    "        teste[\"classe\"] = classificados\n",
    "        ndf_teste = teste.drop(columns=['vetor'])\n",
    "        ndf_treino = treino.drop(columns=['vetor'])\n",
    "        ndf = pd.concat([ndf_treino, ndf_teste]).sort_index()\n",
    "        ndf.to_csv('../dados/classficados.csv', index=False)\n",
    "\n",
    "    def executar(self, dataset, caminho_modelo, operacao='treinar', alg=1):\n",
    "\n",
    "        modelo = Doc2Vec.load(caminho_modelo)\n",
    "        df = pd.read_csv(dataset)\n",
    "        docs_classif, docs_sem_classif = self.pre_proc(df)\n",
    "        self.dataset_treino(docs_classif, docs_sem_classif, modelo)\n",
    "        if operacao == 'treinar':\n",
    "            self.treinar(docs_classif, alg)\n",
    "        elif operacao == 'classif':\n",
    "            self.classificar(docs_classif, docs_sem_classif, alg)\n",
    " \n",
    "    def data_set(self, dataset, caminho_modelo):\n",
    "        modelo = Doc2Vec.load(caminho_modelo)\n",
    "        df = pd.read_csv(dataset)\n",
    "        docs_classif, docs_sem_classif = self.pre_proc(df)\n",
    "        self.dataset_treino(docs_classif, docs_sem_classif, modelo)\n",
    "        return docs_classif, docs_sem_classif\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi = Classificador()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = classi.data_set(\"../dados/articles_limpo.csv\", 'modelos/doc2vec.text_0_100_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166288"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train) + len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>link</th>\n",
       "      <th>vetor</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
       "      <td>Com a possibilidade de uma condenação impedir ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "      <td>[-0.68763316, 0.296071, -0.29345122, 0.1390960...</td>\n",
       "      <td>poder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
       "      <td>Para Oumou Sangaré, cantora e ativista malines...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "      <td>[-0.122184984, 0.6587932, 0.062461976, -0.0535...</td>\n",
       "      <td>ilustrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
       "      <td>Três reportagens da Folha foram vencedoras do ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "      <td>[-0.56213987, 0.31456754, -0.15940027, 0.30708...</td>\n",
       "      <td>poder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
       "      <td>A Disney divulgou na noite desta segunda-feira...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "      <td>[-0.86896574, 0.59616095, 0.25170445, 0.112854...</td>\n",
       "      <td>ilustrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
       "      <td>O CBSS, banco da holding Elopar dos sócios Bra...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>mercado</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/10/1...</td>\n",
       "      <td>[-0.65253127, 0.46439856, 0.25892583, 0.578771...</td>\n",
       "      <td>mercado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Lula diz que está 'lascado', mas que ainda tem...   \n",
       "1  'Decidi ser escrava das mulheres que sofrem', ...   \n",
       "2  Três reportagens da Folha ganham Prêmio Petrob...   \n",
       "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...   \n",
       "4  CBSS inicia acordos com fintechs e quer 30% do...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  Com a possibilidade de uma condenação impedir ...  2017-09-10      poder   \n",
       "1  Para Oumou Sangaré, cantora e ativista malines...  2017-09-10  ilustrada   \n",
       "2  Três reportagens da Folha foram vencedoras do ...  2017-09-10      poder   \n",
       "3  A Disney divulgou na noite desta segunda-feira...  2017-09-10  ilustrada   \n",
       "4  O CBSS, banco da holding Elopar dos sócios Bra...  2017-09-10    mercado   \n",
       "\n",
       "                                                link  \\\n",
       "0  http://www1.folha.uol.com.br/poder/2017/10/192...   \n",
       "1  http://www1.folha.uol.com.br/ilustrada/2017/10...   \n",
       "2  http://www1.folha.uol.com.br/poder/2017/10/192...   \n",
       "3  http://www1.folha.uol.com.br/ilustrada/2017/10...   \n",
       "4  http://www1.folha.uol.com.br/mercado/2017/10/1...   \n",
       "\n",
       "                                               vetor     classe  \n",
       "0  [-0.68763316, 0.296071, -0.29345122, 0.1390960...      poder  \n",
       "1  [-0.122184984, 0.6587932, 0.062461976, -0.0535...  ilustrada  \n",
       "2  [-0.56213987, 0.31456754, -0.15940027, 0.30708...      poder  \n",
       "3  [-0.86896574, 0.59616095, 0.25170445, 0.112854...  ilustrada  \n",
       "4  [-0.65253127, 0.46439856, 0.25892583, 0.578771...    mercado  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORGANIZANDO OS TESTES \n",
    "X = data_train['vetor'][:]\n",
    "X_test = data_test['vetor'][:]\n",
    "Y_train = data_train['category']\n",
    "Y_test = data_test['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poder', 'ilustrada', 'mercado', 'mundo', 'esporte', 'tec']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = []\n",
    "for cat in Y_train:\n",
    "    if cat not in counter:\n",
    "        counter.append(cat)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADICIONANDO CODIFICAÇÃO AD-HOC das categorias\n",
    "Y = pd.get_dummies(Y_train).values\n",
    "Y_test = pd.get_dummies(Y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# para usar redes do tensor flow é necessario usar  tipo de dados deles.\n",
    "def ndarray_to_tensor(X):\n",
    "    for i in range(len(X)):\n",
    "        X[i] = list(X[i])\n",
    "    X = list(X)\n",
    "    return tf.constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = ndarray_to_tensor(X.values)\n",
    "Y_tensor = ndarray_to_tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99064, 100)\n",
      "(99064, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_tensor.shape)\n",
    "print(Y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contruindo rede neural MLP\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units= 200, activation='relu', input_shape=(X_tensor.shape[1], )))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(units= 100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(units= Y_tensor.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 40,906\n",
      "Trainable params: 40,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### folder: 1/5\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2860 - categorical_accuracy: 0.8996\n",
      "620/620 [==============================] - 0s 679us/step - loss: 0.2233 - categorical_accuracy: 0.9195\n",
      "###### Folder loss: [] Folder acc:  0.9195477962493896\n",
      "##### folder: 1/5\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2146 - categorical_accuracy: 0.9233\n",
      "620/620 [==============================] - 0s 693us/step - loss: 0.2179 - categorical_accuracy: 0.9164\n",
      "###### Folder loss: [0.22330105304718018] Folder acc:  0.9163680672645569\n",
      "##### folder: 1/5\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2001 - categorical_accuracy: 0.9273\n",
      "620/620 [==============================] - 0s 705us/step - loss: 0.1605 - categorical_accuracy: 0.9409\n",
      "###### Folder loss: [0.22330105304718018, 0.2178974449634552] Folder acc:  0.9408974051475525\n",
      "##### folder: 1/5\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1812 - categorical_accuracy: 0.9339\n",
      "620/620 [==============================] - 0s 696us/step - loss: 0.1698 - categorical_accuracy: 0.9326\n",
      "###### Folder loss: [0.22330105304718018, 0.2178974449634552, 0.16049307584762573] Folder acc:  0.9325695037841797\n",
      "##### folder: 1/5\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1636 - categorical_accuracy: 0.9397\n",
      "620/620 [==============================] - 0s 675us/step - loss: 0.1885 - categorical_accuracy: 0.9291\n",
      "###### Folder loss: [0.22330105304718018, 0.2178974449634552, 0.16049307584762573, 0.16984009742736816] Folder acc:  0.9290834069252014\n"
     ]
    }
   ],
   "source": [
    "# gerando o crossvalidation com tensor flow.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    " \n",
    "n_split=5\n",
    "acc = []\n",
    "loss = []\n",
    "y_predito = []\n",
    "y_teste = []\n",
    "count_fold = 1\n",
    "for train_index,test_index in KFold(n_split).split(X.values):\n",
    "    \n",
    "    print('##### folder: {}/{}'.format(count_fold, n_split) )\n",
    "    \n",
    "    x_train,x_test=X.values[train_index],X.values[test_index]\n",
    "    y_train,y_test=Y[train_index],Y[test_index]\n",
    "  \n",
    "    model.fit(ndarray_to_tensor(x_train), ndarray_to_tensor(y_train), epochs = 1)\n",
    "\n",
    "    loss_, acc_ = model.evaluate(ndarray_to_tensor(x_test),\n",
    "                                             ndarray_to_tensor(y_test))\n",
    "    print('###### Folder loss:', loss, \"Folder acc: \", acc_ )\n",
    "    y_teste.append(y_test)\n",
    "    y_pred = model.predict(ndarray_to_tensor(x_test))\n",
    "    y_predito.append(y_pred)\n",
    "    acc.append(acc_)\n",
    "    loss.append(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276932358741761"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acc)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "accu = []\n",
    "\n",
    "for i in range(len(y_teste)):\n",
    "    y_pred = np.argmax(y_predito[i], axis=1)\n",
    "    y_test = np.argmax(y_teste[i], axis=1)\n",
    "\n",
    "    # Print f1, precision, and recall scores\n",
    "    precision.append(precision_score(y_test, y_pred , average=\"macro\"))\n",
    "    recall.append(recall_score(y_test, y_pred , average=\"macro\"))\n",
    "    f1.append(f1_score(y_test, y_pred , average=\"macro\"))\n",
    "    accu.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9039302438949829\n",
      "Recall:  0.9084911066667443\n",
      "F1 Score:  0.9038817559752387\n",
      "Accuracy:  0.9276932224638752\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", sum(precision)/n_split)\n",
    "print(\"Recall: \", sum(recall)/n_split)\n",
    "print(\"F1 Score: \", sum(f1)/n_split)\n",
    "print(\"Accuracy: \", sum(accu)/n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
