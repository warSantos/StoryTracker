{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "caminho_modelo = 'modelos/doc2vec.text_0_100_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['title', 'text', 'date', 'category', 'link'], dtype='object')"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Carregamento do dataset.\n",
    "df = pd.read_csv('../dados/articles_limpo.csv', nrows=5000)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dados/articles_limpo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo doc2vec (títulos).\n",
    "modelo = Doc2Vec.load(caminho_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classificadores import Classificador\n",
    "\n",
    "c =  Classificador()\n",
    "\n",
    "caminho_df = '../dados/articles_limpo.csv'\n",
    "df = pd.read_csv(caminho_df)\n",
    "classif, s_classif = c.pre_proc(df)\n",
    "#treino, teste = c.dataset_treino(classif, s_classif, modelo)\n",
    "c.dataset_treino(classif, s_classif, modelo)\n",
    "clf = LogisticRegression(random_state=0, max_iter=150, solver='sag')#, C=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo.\n",
    "\"\"\"\n",
    "vetores = list()\n",
    "classes = list()\n",
    "for index, row in treino.iterrows():\n",
    "    vetores.append(row['vetor'])\n",
    "    classes.append(row['classe'])\n",
    "\"\"\"\n",
    "\n",
    "#clf.fit(vetores, classes)\n",
    "clf.fit(list(classif['vetor']), list(classif['classe']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificando as novas amostras.\n",
    "vetores = list()\n",
    "for index, row in s_classif.head().iterrows():\n",
    "    vetores.append(row['vetor'])\n",
    "    print(clf.predict([row['vetor']]))\n",
    "#classificados = clf.predict(vetores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(classif['vetor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o Naive Bayes.\n",
    "gnb = GaussianNB()\n",
    "naive = gnb.fit(vetores_treino[:69854], classes_treino[:69854])\n",
    "# 29937\n",
    "#for vetor, classe in zip(vetores_treino[29937:], classes_treino[29937:]):\n",
    "#    naive.predict([vetor, classe])\n",
    "acc = naive.score(vetores_treino[29937:], classes_treino[29937:])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(vetores_treino[:69854], classes_treino[:69854])\n",
    "clf.score(vetores_treino[29000:], classes_treino[29000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "### A partir desta célula a implementação refere-se ao algoritmo TD-IDF\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando o texto.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "df = df[df['text'].notna()]\n",
    "\n",
    "categorias_finais = ['tec', 'esporte', 'ilustrada', 'mercado', 'poder', 'mundo']\n",
    "categorias_diluidas = list(set(df['category']) - set(categorias_finais))\n",
    "\n",
    "# Agrupando coluna de tecnologia com ciência.\n",
    "# df[\"category\"]= df[\"category\"].replace(\"ciencia\", \"tec\")\n",
    "\n",
    "# Criando dataset com categorias finais para teste.\n",
    "docs_classif = df\n",
    "for cat in categorias_diluidas:\n",
    "    docs_classif = docs_classif[docs_classif['category'] != cat]\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "documentos = list()\n",
    "stpw = {}\n",
    "for p in stopwords.words(\"portuguese\"):\n",
    "    stpw[p] = True\n",
    "\n",
    "for row in docs_classif.itertuples():\n",
    "    doc = list()\n",
    "    for p in tokenizer.tokenize(row.text.lower()):\n",
    "        if p not in stpw:\n",
    "            doc.append(p)\n",
    "    documentos.append(' '.join(doc))\n",
    "\n",
    "docs_classif['texto_limpo'] = documentos\n",
    "df_treino = docs_classif[['texto_limpo', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aplicando o tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#instantiate CountVectorizer()\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(df_treino['texto_limpo'])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1-Measure:  [0.26915906 0.30795149 0.29875718 0.26647858 0.28627336]\n"
    }
   ],
   "source": [
    "# Aplicando os algoritimos.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "alg = 4\n",
    "\n",
    "# Regressão Logistica.\n",
    "if alg == 1:\n",
    "    clf = LogisticRegression(random_state=0, max_iter=150, solver='sag')\n",
    "# Naive Bayes.\n",
    "elif alg == 2:\n",
    "    clf = GaussianNB()\n",
    "# Rede Neural.\n",
    "elif alg == 3:\n",
    "    clf = MLPClassifier(solver='adam', hidden_layer_sizes=(100), learning_rate_init=0.002, \\\n",
    "            learning_rate= 'adaptive', max_iter=200)\n",
    "else:\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "scores = cross_val_score(clf, X_train_counts, df_treino['category'], cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "print(\"F1-Measure: \", scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('amb': venv)",
   "language": "python",
   "name": "python36964bitambvenva38dc106775843ce902e0fa5c216c0fd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}